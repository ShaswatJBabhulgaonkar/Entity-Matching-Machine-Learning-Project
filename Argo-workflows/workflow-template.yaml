apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: workflow-template
  namespace: machine-learning-argo-run
spec:
  entrypoint: main
  serviceAccountName: machine-learning-argo-sa
  arguments:
    parameters:
      - name: virtual-cluster-id
        value: cn0e2l2onmf11t2mr7krt8ac2
      - name: execution-role-arn
        value: arn:aws:iam::554187193495:role/EMRContainers-dev-JobExecutionRole
      - name: emr-release-label
        value: emr-6.4.0-20210830
      - name: job-repository
        value: 554187193495.dkr.ecr.us-east-2.amazonaws.com/h1-data-science-ml-em-core
      - name: job-version
        value: dev-222
      - name: env
        value: dev
      - name: spark-executor-instances
        value: 1
      - name: spark-executor-memory
        value: 7G 
      - name: spark-executor-cores
        value: 2 
      - name: spark-driver-memory
        value: 2G 
      - name: spark-driver-cores
        value: 2
     
  templates:
    - name: main
      inputs:
        parameters:
          - name: configuration-overrides
      steps:
        - - name: import
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "import"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/import_data.py"
        - - name: feature-eng
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "feature-eng"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/feature_eng.py"
        - - name: training
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "training"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/training.py"
        - - name: modeling
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "modeling"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/model.py"
        - - name: inference
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "inference"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/inference.py"
        - - name: export
            template: trigger-emr-job
            arguments:
              parameters:
              - name: emr-job-name
                value: "export"
              - name: job-entrypoint
                value: "local:///app/ml_pipeline/export.py"


    - name: trigger-emr-job
      inputs:
        parameters:
          - name: workflowtemplate
            value: "emr-job-template"
          - name: virtual-cluster-id
            value: "{{workflow.parameters.virtual-cluster-id}}"
          - name: execution-role-arn
            value: "{{workflow.parameters.execution-role-arn}}"
          - name: emr-release-label
            value: "{{workflow.parameters.emr-release-label}}"
          - name: job-repository
            value: "{{workflow.parameters.job-repository}}"
          - name: job-version
            value: "{{workflow.parameters.job-version}}"
          - name: configuration-overrides
            value: "{{workflow.parameters.configuration-overrides}}"
          - name: spark-executor-instances
            value: "{{workflow.parameters.spark-executor-instances}}"
          - name: spark-executor-memory
            value: "{{workflow.parameters.spark-executor-memory}}"
          - name: spark-executor-cores
            value: "{{workflow.parameters.spark-executor-cores}}"
          - name: spark-driver-memory
            value: "{{workflow.parameters.spark-driver-memory}}"
          - name: spark-driver-cores
            value: "{{workflow.parameters.spark-driver-cores}}"
          - name: emr-job-name
          - name: job-entrypoint
          - name: args-entrypoint
            value: '[]'

      resource:
        action: create
        manifest: |
          apiVersion: argoproj.io/v1alpha1
          kind: Workflow
          metadata:
            generateName: {{inputs.parameters.emr-job-name}}-
          spec:
            serviceAccountName: machine-learning-argo-sa
            arguments:
              parameters:
              - name: virtual-cluster-id
                value: {{inputs.parameters.virtual-cluster-id}}
              - name: emr-job-name
                value: {{inputs.parameters.emr-job-name}}
              - name: execution-role-arn
                value: {{inputs.parameters.execution-role-arn}}
              - name: emr-release-label
                value: {{inputs.parameters.emr-release-label}}
              - name: job-repository
                value: {{inputs.parameters.job-repository}}
              - name: job-version
                value: {{inputs.parameters.job-version}}
              - name: job-entrypoint
                value: {{inputs.parameters.job-entrypoint}}
              - name: configuration-overrides
                value: '{{inputs.parameters.configuration-overrides}}'
              - name: spark-executor-instances
                value: "{{inputs.parameters.spark-executor-instances}}"
              - name: spark-executor-memory
                value: "{{inputs.parameters.spark-executor-memory}}"
              - name: spark-executor-cores
                value: "{{inputs.parameters.spark-executor-cores}}"
              - name: spark-driver-memory
                value: "{{inputs.parameters.spark-driver-memory}}"
              - name: spark-driver-cores
                value: "{{inputs.parameters.spark-driver-cores}}"
            
            workflowTemplateRef:
              name: {{inputs.parameters.workflowtemplate}}
        successCondition: status.phase == Succeeded
        failureCondition: status.phase in (Failed, Error)